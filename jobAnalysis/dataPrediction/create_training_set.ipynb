{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import glob\n",
    "import itertools\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.gridspec as gridspec\n",
    "from sklearn import metrics\n",
    "\n",
    "from include import features\n",
    "from common.textClean import textClean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1447"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df = pd.read_csv('data/model_data_test.csv')\n",
    "df = pd.read_pickle('./data/training_set/training_set.pkl')\n",
    "#df = df.drop('Unnamed: 0', axis=1)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the lists into separated columns\n",
    "\n",
    "# tags\n",
    "tags = pd.DataFrame(df['tags'].values.tolist())\n",
    "tags.columns = ['tags_{}'.format(str(int(x)+1)) for x in tags.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.drop('tags', axis=1, inplace=True)\n",
    "# subject area\n",
    "#subjects = df['subject_area'].str.replace(\"'\", \"\").str.replace(']', '').str.replace('[', '').str.replace(' ', '').str.split(',', expand=True)\n",
    "subjects = pd.DataFrame(df['subject_area'].values.tolist())\n",
    "\n",
    "subjects.columns = ['subject_{}'.format(str(int(x)+1)) for x in subjects.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, tags, subjects], axis=1, sort=False)\n",
    "\n",
    "# Create a columns with the number of existing tags\n",
    "df['tag_count'] = df[tags.columns].count(axis=1)\n",
    "# Drop rows that have only one tag\n",
    "df = df[df['tag_count'] > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The prediction are in the way to predict if the job is a NOT software job. Inverse the score to make it easier to read\n",
    "col_proba = [x for x in df.columns if x[-6:] == '_proba']\n",
    "for col in col_proba:\n",
    "    df[col_proba] = df[col_proba].apply(lambda x: 1-x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating different tags from the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def previous_tags(row):\n",
    "    insuff = 0\n",
    "    no = 0\n",
    "    some = 0\n",
    "    most = 0\n",
    "    if row[-1] != 'third_run':\n",
    "        for r in row[:-1]:\n",
    "            if r == 'No':\n",
    "                no +=1\n",
    "            elif r == 'Some':\n",
    "                some +=1\n",
    "            elif r == 'Most':\n",
    "                most +=1\n",
    "            elif r == 'Insufficient Evidence':\n",
    "                insuff +=1\n",
    "            else:\n",
    "                pass\n",
    "        if most >= 2:\n",
    "            return 1\n",
    "        elif some >=2:\n",
    "            return 1\n",
    "        elif no >=2:\n",
    "            return 0\n",
    "        elif insuff >=2:\n",
    "            return 'Insufficient Evidence'\n",
    "        else:\n",
    "            return 'Ambiguous'\n",
    "    else:\n",
    "        return 'third_run'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_tags(row):\n",
    "    insuff = 0\n",
    "    no = 0\n",
    "    some = 0\n",
    "    most = 0\n",
    "    for r in row:\n",
    "        if r == 'No':\n",
    "            no +=1\n",
    "        elif r == 'Some':\n",
    "            some +=1\n",
    "        elif r == 'Most':\n",
    "            most +=1\n",
    "        elif r == 'Insufficient Evidence':\n",
    "            insuff +=1\n",
    "        else:\n",
    "            pass\n",
    "    if insuff >= 2:\n",
    "        return 'Insufficient Evidence'\n",
    "    elif no >=2:\n",
    "        return 'No'\n",
    "    elif some >=2:\n",
    "        return 'Some'\n",
    "    elif most >= 2:\n",
    "        return 'Most'\n",
    "    elif no == 1 and some ==1 and most == 0:\n",
    "        return 'No'\n",
    "    elif no ==1 and most ==1 and some == 0:\n",
    "        return  'Some'\n",
    "    elif some == 1 and most ==1 and no == 0:\n",
    "        return 'Some'\n",
    "    elif no == 1 and some == 1 and most == 1:\n",
    "        return 'Insufficient Evidence'\n",
    "    elif insuff ==1 and some ==1 and most ==1:\n",
    "        return 'Some'\n",
    "    elif insuff ==1 and no ==1 and most == 1:\n",
    "        return 'Insufficient Evidence'\n",
    "    elif insuff ==1 and some ==1 and no ==1:\n",
    "        return 'No'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_score(row):\n",
    "    \"\"\"\n",
    "    This function aggregate the different tags given by people to a job ads into an integrate one, computed with the\n",
    "    mean and some other calculation to reflect the different possibilities given.\n",
    "    The different possibilities were:\n",
    "        1. Insufficient evidence: no enough information to see if the jobs ads requires software development or not\n",
    "        2. None: no software development required\n",
    "        3. Some: some software development required\n",
    "        4. Most: mainly software development\n",
    "    For the rest it transform the different category into numerical value\n",
    "        . None: 0\n",
    "        . Some: 1\n",
    "        . Most: 2\n",
    "    From there, the mean is calculated. and from the result the three category are recreated\n",
    "        . [0, 0.33, 0.5]: None\n",
    "        . [0.6, 1]: Some\n",
    "        . > 1: Most\n",
    "    If there is one insufficient information among the tags, it negative the mean. If there is a consensus of Insufficient\n",
    "    Information it gives a -10\n",
    "    \n",
    "    :params:\n",
    "        df: containing the columns to compute\n",
    "    :return:\n",
    "        a panda Series with the computated mean\n",
    "    \"\"\"\n",
    "    list_values = list()\n",
    "    insufficient = 0\n",
    "    for r in row:\n",
    "        if r == 'No':\n",
    "            list_values.append(0)\n",
    "        elif r == 'Some':\n",
    "            list_values.append(1)\n",
    "        elif r == 'Most':\n",
    "            list_values.append(2)\n",
    "        elif r == 'Insufficient Evidence':\n",
    "            insufficient +=1\n",
    "        else:\n",
    "            pass\n",
    "    if insufficient > 1:\n",
    "        return -10\n",
    "    elif insufficient == 1:\n",
    "        if len(list_values) == 1:\n",
    "            return -0\n",
    "        elif len(list_values) == 0:\n",
    "            return -10\n",
    "        else:\n",
    "            return (-(sum(list_values) / float(len(list_values))))/2\n",
    "    else:\n",
    "        if len(list_values) == 1:\n",
    "            return 0\n",
    "        else:\n",
    "            return (sum(list_values) / float(len(list_values)))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.000000     726\n",
       " 1.000000     112\n",
       " 0.166667     100\n",
       " 0.750000      99\n",
       " 0.500000      97\n",
       "-0.250000      49\n",
       "-10.000000     46\n",
       " 0.333333      45\n",
       "-0.500000      35\n",
       " 0.250000      20\n",
       "-0.750000      12\n",
       " 0.666667       7\n",
       "-1.000000       7\n",
       "Name: agg_tag, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['agg_tag'] = df.loc[:, ['tags_1', 'tags_2', 'tags_3']].apply(calculate_score, axis=1)\n",
    "df['agg_tag'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    986\n",
       "1    369\n",
       "Name: agg_created_tag, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['agg_created_tag'] = df['agg_tag'].apply(lambda x: 1 if abs(x)>=.5 and abs(x) < 10 else 0)\n",
    "df['agg_created_tag'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No              826\n",
       "Some            246\n",
       "Most            237\n",
       "Insufficient     46\n",
       "Name: new_tag_agg, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new tag with more category than before, adding insufficient, Some. \n",
    "# at the end, there are 4 categories\n",
    "# 1. Insufficient evidence: score == -10\n",
    "# 2. No: abs(0.2) < score < abs(0.6)\n",
    "# 3. Some: \n",
    "# 4. Most: abs(0.6) < score <=1\n",
    "\n",
    "def new_tag_agg(score):\n",
    "    if score == -10:\n",
    "        return 'Insufficient'\n",
    "    elif abs(score) >=0 and abs(score) < 0.2:\n",
    "        return 'No'\n",
    "    elif abs(score) >= 0.2 and abs(score) < 0.6:\n",
    "        return 'Some'\n",
    "    elif abs(score) > 0.6 and abs(score) <= 1:\n",
    "        return 'Most'\n",
    "\n",
    "df['new_tag_agg'] = df.loc[:, 'agg_tag'].apply(new_tag_agg)\n",
    "df['new_tag_agg'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                        795\n",
       "1                        215\n",
       "Ambiguous                200\n",
       "third_run                100\n",
       "Insufficient Evidence     45\n",
       "Name: previous_tags, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['previous_tags'] = df.loc[:, ['tags_1', 'tags_2', 'tags_3', 'run_tag']].apply(previous_tags, axis=1)\n",
    "df['previous_tags'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No                       893\n",
       "Some                     253\n",
       "Most                     126\n",
       "Insufficient Evidence     71\n",
       "Name: new_tags, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['new_tags'] = df.loc[:, ['tags_1', 'tags_2', 'tags_3']].apply(new_tags, axis=1)\n",
    "df['new_tags'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/olivier/.data/git/ssi/jobs-analysis/venv/lib/python3.6/site-packages/pandas/core/indexing.py:1472: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                        795\n",
       "1                        215\n",
       "Ambiguous                200\n",
       "third_run                100\n",
       "Insufficient Evidence     45\n",
       "Name: original_tags, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def corresponding_prev_train(col):\n",
    "    for c in col:\n",
    "        try:\n",
    "            if int(col[0]) == int(col[1]):\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "        except ValueError:\n",
    "            return col[0]\n",
    "\n",
    "df['original_tags'] = df.loc[:, ['previous_tags', 'prediction']].apply(corresponding_prev_train, axis=1)\n",
    "\n",
    "df['original_tags'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1040\n",
       "1     315\n",
       "Name: final_bool_tags, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create new tags\n",
    "df['final_bool_tags'] = np.where(df['agg_tag']>=0.5, 1, 0)\n",
    "df['final_bool_tags'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('./data/training_set/training_set_mod.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
