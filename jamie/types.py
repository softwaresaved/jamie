# Custom types and enums for use in Jamie
import re
import json
import numpy as np
import pandas as pd
from bson.json_util import loads
import datetime
from enum import Enum, auto
from typing import Optional, List
from dataclasses import dataclass, asdict


def _get_mongo_date(record, key):
    if key in record and record[key] is not None and "$date" in record[key]:
        return loads(json.dumps(record[key])).date()
    return None


class Alert(Enum):
    "Alert levels for reporting"
    High = 3
    Medium = 2
    Low = 1

    @staticmethod
    def level(n):
        if n > 0.80:
            return Alert.High
        elif n > 0.60:
            return Alert.Medium
        else:
            return Alert.Low

    @property
    def tag(self):
        return self.name.lower()


class PrecisionRecall(Enum):

    High = """Both precision and recall are high. The model captures most
of the target job type as well as being precise and avoiding false
negatives. The reported estimates can be considered a good estimate for the
target job type."""

    Low = """Both precision and recall are low or average. The model can neither
correctly classify most of the positives, nor is it precise. The reported estimates
are unreliable for the target job type."""

    HighLow = """Precision is high while recall is low or average. The model is
conservative; the target job type is precisely identified with few
false positives, but in doing so, the model fails to identify many
jobs. The reported estimates should be considered an underestimate for
the target job type."""

    LowHigh = """"Precision is low or average while recall is high. The model is
overpredicting, that is predicting more jobs in the target job type than
actual, thus leading to low precision; while recall is high because of
the overprediction. The reported estimates should be considered an overestimate
for the target job type."""

    @staticmethod
    def get(precision, recall):
        return_map = {
            (True, True): PrecisionRecall.High,
            (False, False): PrecisionRecall.Low,
            (True, False): PrecisionRecall.HighLow,
            (False, True): PrecisionRecall.LowHigh,
        }
        return return_map[precision == Alert.High, recall == Alert.High]

    @property
    def alert(self):
        if self.name == "High":
            return Alert.High
        elif self.name == "Low":
            return Alert.Low
        else:
            return Alert.Medium


class Contract(Enum):
    "Contract type: Fixed Term or Permanent"
    FixedTerm = auto()
    Permanent = auto()


class JobType(Enum):
    rse = {
        "title": "Research Software",
        "search_keywords": ["research", "software"],
    }

    @property
    def title(self):
        return self.value["title"]

    @property
    def search_keywords(self):
        return self.value["search_keywords"]


@dataclass
class JobPrediction:
    """Represents prediction for a single job

    Attributes
    ----------
    jobid : str
        JobID from jobs.ac.uk
    job_title : str
        Job title
    snapshot : str
        Model snapshot used for prediction
    closes : datetime.date
        Close date for job
    contract : Contract
        Contract type
    department : str
        Department of the academic institution that
        the job is associated with
    employer : str
        Job employer
    date : datetime.date
        Date of the job. This is usually the same as the posted date,
        but if that is not available, defaults to the date of job applications
        closing, or the earliest date found in the job description. This
        attribute should be used for computing timeseries.
    posted : datetime.date
        Date job was posted
    extra_location : str
        Broad geographical location of job position
    salary_min : Optional[int]
        Minimum salary associated with the job. Sometimes
        jobs have a range of salaries depending on the experience
        of the applicant.
    salary_max : Optional[int]
        Maximum salary associated with the job. Sometimes
        jobs have a range of salaries depending on the experience
        of the applicant.
    salary_median : Optional[int]
        Median salary associated with the job.
    probability : float
        Probability that the job is classified in the positive class
    probability_lower : float
        Lower confidence interval of the probability
    probability_upper : float
        Upper confidence interval of the probability

    Parameters
    ----------
    prediction : dict
        Dictionary representing a single prediction from the JSONL file
        generated by :class:`Predict`
    """

    jobid: str
    snapshot: str
    contract: str
    employer: str
    hours: List[str]
    job_title: str
    date: datetime.date
    posted: datetime.date
    extra_location: str
    probability: float
    probability_lower: float
    probability_upper: float
    department: Optional[str] = None
    location: Optional[str] = None
    salary_max: Optional[float] = None
    salary_min: Optional[float] = None
    salary_median: Optional[float] = None

    def __init__(self, prediction):
        self.jobid = prediction["jobid"]
        self.snapshot = prediction["snapshot"]
        if "contract" in prediction:
            self.contract = (
                Contract.Permanent
                if prediction["contract"] == "Permanent"
                else Contract.FixedTerm
            )
        else:
            self.contract = None
        self.employer = prediction.get("employer", None)
        self.hours = prediction.get("hours", None)
        self.job_title = prediction["job_title"]
        self.department = prediction.get("department", None)
        self.location = prediction.get("location", None)
        self.extra_location = prediction.get("extra_location", None)
        self.salary_max = prediction.get("salary_max", None)
        self.salary_min = prediction.get("salary_min", None)
        self.salary_median = prediction.get("salary_median", None)
        for p in ["probability", "lower_ci", "upper_ci"]:
            if not 0 <= prediction[p] <= 1:
                raise ValueError(
                    "Tried reading invalid {}={}.".format(p, prediction[p])
                )
        self.probability = prediction["probability"]
        self.probability_lower = prediction["lower_ci"]
        self.probability_upper = prediction["upper_ci"]
        self.posted = _get_mongo_date(prediction, "placed_on")
        self.date = _get_mongo_date(prediction, "date")
        closes = _get_mongo_date(prediction, "closes")
        self.date = self.date or self.posted or closes  # select first non-null

    def to_dict(self):
        return asdict(self)


@dataclass
class TrainingData:
    """Schema for the training dataset.

    Required columns for model training are 'description', 'job_title',
    'aggregate_tags'. The attribute 'placed_on' is required for timeseries
    graphs of the training data.

    Parameters
    ----------
    description : str
        Job description
    job_title : str
        Job title
    aggregate_tags : int
        Integer equals 0 or 1
    placed_on : datetime.date
        Date job was placed on
    jobid : str
        Unique jobid given by jobs.ac.uk
    job_ref : str
        Job reference, possibly used internally by the employer
    contract : str
        Contract type, fixed term or permanent, full-time or part-time
    department : str
        Department of the employer
    duration_ad_days : int
        Duration of job advertisment in days from placed_on to closes.
    employer : str
        Employer name
    enhanced : str
        HTML content can be "enhanced" or "normal", which alters the parsing
    extra_location : str
        Region of UK where job is from
    final_bool : int
        *Unknown* boolean type
    funding_amount : Optional[str]
        Funding amount text if for a PhD position
    funding_for: Optional[str]
        Specifies whether funding is for UK, EU, international or self-funded students
    hours : str
        Specifies whether job is full time or part time
    in_uk : bool
        Specifies whether job is actually in the UK. Some jobs are by UK institutions
        but located overseas
    invalid_code : Optional[List[str]]
        List of job attributes that could not be parsed
    json : Optional[str]
        JSON representation of job
    location : str
        City where job is located
    not_student : bool
        Whether job is a PhD level position
    original : int
        *Unknown* boolean type
    original_proba : float
        *Unknown* probability
    qualification_type : str
        Type of qualification required for the job in term of education level
    reference : str
        Unknown field
    region : str
        Unknown field, possibly country of the UK where job is
    run_tag : str
        Whether job was classified in first or second run
    salary : str
        Text fragment which has information on salary
    salary_max : Optional[float]
        If a salary range is specified, higher end of the salary range, otherwise same
        as median salary
    salary_min : Optional[float]
        If a salary range is specified, lower end of the salary range, otherwise same
        as median salary
    salary_median : Optional[float]
        Median of salary_min, salary_max if both are present, otherwise equals
        the salary value
    subject_area : List[str]
        List of academic fields for the job
    tags : List[str]
        List of tags (labels) given by coders to the job
    tags_1, tags_2 : str
        Label given to job given by coder 1 and 2 respectively,
        one of {'No', 'Some', 'Insufficient Evidence', 'Most'} when answering the question
        "How much time would be spent in this job developing software?"
    tags_3 : Optional[str]
        Label given to job by coder 3 when coder 1 and coder 2 disagreed
    tag_count : int
        Number of coders who classified the job
    agg_tags : float
        Aggregate score from coders
    aggregate_tags : int
        Classification of whether the job is in the target class or not
        (1 indicating it is, 0 otherwise)
    multi_agg_tags : str
        Unknown field
    consensus_tags : str
        [tentative] Consensus of tags_1 and tags_2
    diff_consensus_tags : str
        Unknown field
    """

    description: str
    job_title: str
    aggregate_tags: int
    placed_on: datetime.date
    jobid: str
    job_ref: str
    contract: str
    department: str
    duration_ad_days: int
    employer: str
    enhanced: str
    extra_location: str
    final_bool: int
    funding_amount: Optional[str]
    funding_for: Optional[str]
    hours: str
    in_uk: bool
    invalid_code: Optional[List[str]]
    json: Optional[str]
    location: str
    not_student: bool
    original: int
    original_proba: float
    qualification_type: str
    reference: str
    region: str
    run_tag: str
    salary: str
    salary_max: Optional[float]
    salary_min: Optional[float]
    salary_median: Optional[float]
    subject_area: List[str]
    tags: List[str]
    tags_1: str
    tags_2: str
    tags_3: Optional[str]
    tag_count: int
    agg_tags: float
    aggregate_tags: int
    multi_agg_tags: str
    consensus_tags: str
    diff_consensus_tags: str

    def validate(self):
        "Validates a single row of training set data"
        contract_re = re.compile(".*(Fixed-Term|Permanent|Temporary).*", re.IGNORECASE)
        allowed_tags = ["No", "Some", "Insufficient Evidence", "Most"]
        return all(
            (
                self.tags_1 in allowed_tags and self.tags_2 in allowed_tags,
                self.enhanced in ["normal", "enhanced"],
                contract_re.match(self.contract),
            )
        )

    @staticmethod
    def reliability(data, coders=3):
        "Returns DataFrame which can be used to compute reliability"
        if not isinstance(data, pd.DataFrame):
            data = pd.read_csv(data)
        ordinal = {"No": 1, "Some": 2, "Most": 3, "Insufficient Evidence": np.nan}
        for i in range(1, coders + 1):
            data["coder%d" % i] = data["tags_%d" % i].map(ordinal.get)
        data = data.set_index("jobid")
        return data[["coder%d" % i for i in range(1, coders + 1)]]
